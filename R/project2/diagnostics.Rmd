### Diagnostics

#### Assessing Linearity between Xs and Y

```{r, echo=FALSE}

#linear model
best_model
a2$ei = best_model$residuals
a2$yhat = best_model$fitted.values
#beta confidence interval
g = 4 #b0, b5, b{6, run}, b{6, swim}
confint(best_model, level = 0.99/g) #This uses the Bonferroni
a2.CI.sim = confint(best_model, level=0.99)
a2.CI.sim[-1,]
a2.CI.b5 = a2.CI[2,]
a2.CI.b6r = a2.CI[3,]
a2.CI.b6s = a2.CI[4,]
#summary/hypothesis testing
a2.sum = summary(best_model)
a2.HT = a2.sum$coefficients
#estimated regression line
a2.b0 = a2.HT[1]
a2.b5 = a2.HT[2]
a2.b6r = a2.HT[3]
a2.b6s = a2.HT[4]
#divide by 2 for one-tailed test
#t-statistic
a2.b0.t = a2.HT[1, 3]/2
a2.b5.t = a2.HT[2, 3]/2
a2.b6r.t = a2.HT[3, 3]/2
a2.b6s.t = a2.HT[4, 3]/2
#p-value
a2.b0.p = a2.HT[1, 4]/2
a2.b5.p = a2.HT[2, 4]/2
a2.b6r.p = a2.HT[3, 4]/2
a2.b6s.p = a2.HT[4, 4]/2
```

Based on our data with outliers removed, our estimated regression line is:


*Confidence Interval of $b_1$*

We are 99% confident that that when X changes by 1 unit, the estimated change of Y increases, on average, between `r a2.CI.b1[1]` and `r a2.CI.b1[2]`. Since zero is not included in the confidence interval of $b_1$ and is strictly positive, a statistically significant positive relationship is suggested between Y and X.

*Hypothesis Testing of $b_1$*

$H_0$: There is no significant positive linear relationship between Y and X

$H_A$: There is a significant positive linear relationshp between Y and X

Assuming that the null is true, our data or more extreme has the probability `r a2.HT.b1.p` which is less than $\alpha = 0.01$. Thus, we reject the null hypothesis and accept the alternative hypothesis that there is a significant positive linear relationship.

#### Assessing Assumption 1: Normality

```{r, echo=FALSE, message=FALSE}
#simple linear model
a2$ei = best_model$residuals
a2$yhat = best_model$fitted.values
##ASSESSING NORMALITY
# I. QQ Plot
x <- qqnorm(best_model$residuals)
x <- qqline(best_model$residuals)
# II. Shapiro-Wilks
#H0: The errors are normally distributed
#HA: The errors are NOT normally distributed
a2.ei = best_model$residuals
a2.SWtest = shapiro.test(a2.ei)
sw_p = a2.SWtest[2]
```

##### Shaprio-Wilks

$H_0:$ The errors are normally distributed

$H_A:$ The errors are NOT normally distributed

Since our data or more extreme has the probability of `r sw_p` or more extreme, our data for the Shapiro-Wilks Test has **failed to reject** the null hypothesis for $\alpha = 0.05$, and so we accept the null hypothesis that our our data is normally distributed.

#### Assessing Assmption 2: Constant Variance (Homoscedasticity)

```{r, echo=FALSE, message=FALSE}
##ASSESSING CONSTANT VARIANCE (homoscedasticity)
#III. Scatterplot, ei vs Fitted Values
ggplot(a2, 
       aes(x = yhat, y = ei)) +
  geom_smooth(method='lm', se = FALSE, color = "green", size = 0.4) +
  geom_point(size=1, shape=18) +
  ggtitle("Case 1: Errors vs. Fitted Values") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ylab("Errors") +
  xlab("Fitted Values")
#IV. Histogram, ei
ggplot(a2,
       aes(x = ei)) + 
  geom_histogram(binwidth = 1, color = "black",fill = "white") + 
  xlab("ei") + 
  ggtitle("Case 1: Residuals") +
  theme(plot.title = element_text(hjust = 0.5))
#V. Fligner Killeen (FK) test
#H0 \sigma_lower^2 == \sigma_upper^2
#H0 \sigma_lower^2 != \sigma_upper^2
Group = rep("Lower",nrow(a2))
Group[a2$Y > median(a2$Y)] = "Upper"
Group = as.factor(Group)
a2$Group = Group
a2.FKtest = fligner.test(a2$ei, a2$Group)
fk_p = a2.FKtest[3]
#### Summary, Case 1: Outliers Removed
##### Assessing Normality
#I. QQPlot - PASS (improved)
#II. SW - PASS (improved)
##### Assessing Constant Variance
#III. Scatterplot: ei vs Fitted Values - FAILED (cone shaped)
#IV. Histogram of ei - PASS
#V. FK - PASS, barely (improved H0)

```

#####Fligner-Killen (FK) Test

$H_0: \sigma_{lower} ^2 = \sigma_{upper} ^2$

$H_0: \sigma_{lower} ^2 \neq \sigma_{upper} ^2$

Since our data or more extreme has the probability of `r fk_p` or more extreme, our data for the Fligner-Killen Test has *barely* **failed to reject** the null hypothesis for $\alpha = 0.05$, and so we accept the null hypothesis that our our data maintains constant variance.

### Summary: Outliers Removed

##### Assessing Normality

I. QQPlot - PASS (improved)

II. SW - PASS (improved)

##### Assessing Constant Variance

III. Scatterplot: ei vs Fitted Values - FAILED (improved)

IV. Histogram of ei - PASS (improved)

V. FK - PASS (improved, barely pass)