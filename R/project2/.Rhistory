a2 <- a
names(a2) <- c("Y", "X1", "X2", "X3", "X4", "X5", "X6") #use a2 for non-descriptive X names
full.model = lm(Y~ X1 + X2 + X3 + X4 + X5 + X6, data = a2)
all.models = regsubsets(Y ~., data = a2)
library(gridExtra)
library(gclus)
library(leaps)
Partial.R2 = function(small.model,big.model){ #note, models switched
SSE1 = sum(small.model$residuals^2)
SSE2 = sum(big.model$residuals^2)
PR2 = (SSE1 - SSE2)/SSE1
return(PR2)
}
All.Criteria = function(the.model){
p = length(the.model$coefficients)
n = length(the.model$residuals)
the.LL = logLik(the.model)
the.BIC =  -2*the.LL + log(n)*p
the.AIC =  -2*the.LL + 2*p
the.PRESS = PRESS(the.model)
the.R2adj = summary(the.model)$adj.r.squared
the.results = c(the.LL,p,n,the.AIC,the.BIC,the.PRESS,the.R2adj)
names(the.results) = c("LL","p","n","AIC","BIC","PRESS","R2adj")
return(the.results)
}
h_lbm <- ggplot(a,
aes(x = lbm)) +
geom_histogram(binwidth = 4, color = "black",fill = "white") +
xlab("lbm") +
ggtitle("X1: Lean Body Mass") +
theme(plot.title = element_text(hjust = 0.5))
h_bmi <- ggplot(a,
aes(x = bmi)) +
geom_histogram(binwidth = 1, color = "black",fill = "white") +
xlab("bmi") +
ggtitle("X2: Body Mass Index") +
theme(plot.title = element_text(hjust = 0.5))
h_pcBfat <- ggplot(a,
aes(x = pcBfat)) +
geom_histogram(binwidth = 1, color = "black",fill = "white") +
xlab("pcBfat") +
ggtitle("X3: Percent Body Fat") +
theme(plot.title = element_text(hjust = 0.5))
h_ferr <- ggplot(a,
aes(x = ferr)) +
geom_histogram(binwidth = 10, color = "black",fill = "white") +
xlab("ferr") +
ggtitle("X4: Plasma Ferritins") +
theme(plot.title = element_text(hjust = 0.5))
library(ggplot2)
h_lbm <- ggplot(a,
aes(x = lbm)) +
geom_histogram(binwidth = 4, color = "black",fill = "white") +
xlab("lbm") +
ggtitle("X1: Lean Body Mass") +
theme(plot.title = element_text(hjust = 0.5))
h_bmi <- ggplot(a,
aes(x = bmi)) +
geom_histogram(binwidth = 1, color = "black",fill = "white") +
xlab("bmi") +
ggtitle("X2: Body Mass Index") +
theme(plot.title = element_text(hjust = 0.5))
h_pcBfat <- ggplot(a,
aes(x = pcBfat)) +
geom_histogram(binwidth = 1, color = "black",fill = "white") +
xlab("pcBfat") +
ggtitle("X3: Percent Body Fat") +
theme(plot.title = element_text(hjust = 0.5))
a <- read.csv("/Volumes/WD Red HDD/Duke/Dropbox/Documents/108 - STA, linear regression/Homework/project2/athlete.csv")
h_lbm <- ggplot(a,
aes(x = lbm)) +
geom_histogram(binwidth = 4, color = "black",fill = "white") +
xlab("lbm") +
ggtitle("X1: Lean Body Mass") +
theme(plot.title = element_text(hjust = 0.5))
h_pcBfat <- ggplot(a,
aes(x = pcBfat)) +
geom_histogram(binwidth = 1, color = "black",fill = "white") +
xlab("pcBfat") +
ggtitle("X3: Percent Body Fat") +
theme(plot.title = element_text(hjust = 0.5))
h_ferr <- ggplot(a,
aes(x = ferr)) +
geom_histogram(binwidth = 10, color = "black",fill = "white") +
xlab("ferr") +
ggtitle("X4: Plasma Ferritins") +
theme(plot.title = element_text(hjust = 0.5))
grid.arrange(h_lbm, h_bmi, h_pcBfat, h_ferr, ncol=2)
h_bmi <- ggplot(a,
aes(x = bmi)) +
geom_histogram(binwidth = 1, color = "black",fill = "white") +
xlab("bmi") +
ggtitle("X2: Body Mass Index") +
theme(plot.title = element_text(hjust = 0.5))
grid.arrange(h_lbm, h_bmi, h_pcBfat, h_ferr, ncol=2)
dta <- a[c(1,2,3,4,5)] #grab only numerical cols
dta.r <- abs(cor(dta)) #get correlations
dta.col <- dmat.color(dta.r) #get colors
dta.o <-  order.single(dta.r) #reorder variables so those with highest corr are closest to diagonal
cpairs(dta, dta.o, panel.colors=dta.col, gap=0.5,
main="Athlete Variables Ordered and Colored by Correlation")
```{r, echo=FALSE}
dta_cat <- a[c(1,6,7)]
plot(dta_cat)
a2 <- a
names(a2) <- c("Y", "X1", "X2", "X3", "X4", "X5", "X6") #use a2 for non-descriptive X names
full.model = lm(Y~ X1 + X2 + X3 + X4 + X5 + X6, data = a2)
all.models = regsubsets(Y ~., data = a2)
some.stuff = summary(all.models)
names.of.data = c("Y",colnames(some.stuff$which)[-1])
n= nrow(a2) #Will have to change the name
K = nrow(some.stuff$which)
nicer = lapply(1:K,function(i){
model = paste(names.of.data[some.stuff$which[i,]],collapse = ",")
p = sum(some.stuff$which[i,])
BIC = some.stuff$bic[i]
CP = some.stuff$cp[i]
results = data.frame(model,p,CP,BIC)
return(results)
})
nicer = Reduce(rbind,nicer)
nicer
type(nicer)
typeof(nicer)
all.models
full.model = lm(Y~ X1 + X2 + X3 + X4 + X5 + X6, data = a2)
all.models = regsubsets(Y ~., data = a2)
some.stuff = summary(all.models)
all.models
some.stuff
nicer
some.stuff
all.models
some.stuff
nicer
some.stuff
full.model = lm(Y~ X1 + X2 + X3 + X4 + X5 + X6, data = a2)
empty.model = lm(Y ~ 1,data = a2)
library(MASS) #stepwise regression
n = nrow(a2)
forward.model.AIC = stepAIC(empty.model, scope = list(lower = empty.model, upper = full.model), k=2, direction="foward")
forward.model.AIC = stepAIC(empty.model, scope = list(lower = empty.model, upper = full.model), k=2, direction="forward")
forward.model.BIC = stepAIC(empty.model,  scope = list(lower = empty.model, upper= full.model), k = log(n),direction = "forward")
forward.model.AIC = stepAIC(empty.model, scope = list(lower = empty.model, upper = full.model), k=2, direction="forward", trace=FALSE)
forward.model.BIC = stepAIC(empty.model,  scope = list(lower = empty.model, upper = full.model), k=log(n), direction="forward")
forward.model.BIC = stepAIC(empty.model,  scope = list(lower = empty.model, upper = full.model), k=log(n), direction="forward", trace=FALSE)
forward.model.BIC$coefficients
nicer
nicer[which.max(nicer$BIC),])
nicer[which.max(nicer$BIC),]
nicer[which.min(nicer$BIC),]
forward.model.AIC$coefficients
forward.model.BIC$coefficients
forward.model.AIC$coefficients
FB.model.BIC
FB.model.AIC = stepAIC(empty.model, scope = list(lower=empty.model, upper= full.model), k=2, direction="both", trace=FALSE)
FB.model.BIC = stepAIC(empty.model, scope = list(lower=empty.model, upper= full.model), k=log(n), direction="both", trace=FALSE)
FB.model.BIC
full.model = lm(Y~ X1 + X2 + X3 + X4 + X5 + X6, data = a2)
empty.model = lm(Y ~ 1,data = a2)
FB.model.BIC
FB.model.AIC = stepAIC(empty.model, scope = list(lower=empty.model, upper= full.model), k=2, direction="both", trace=FALSE)
FB.model.BIC = stepAIC(empty.model, scope = list(lower=empty.model, upper= full.model), k=log(n), direction="both", trace=FALSE)
FB.model.BIC
FB.model.BIC$coefficients[1]
betas_1 = FB.model.BIC$coefficients[1]
betas_1
betas_1 = FB.model.BIC$coefficients
betas_1
best_model
a2$ei = best_model$residuals
best_model = FB.model.BIC
best_model
a2$ei = best_model$residuals
a2$ei
a2$yhat = best_model$fitted.values
confint(best_model, level = 0.99)
a2.CI = confint(best_model, level=0.99)
a2.CI
a2.CI[-1,]
confint(best_model, level = 0.99/g) #This uses the Bonferroni
g = 4
confint(best_model, level = 0.99/g) #This uses the Bonferroni
a2.CI.sim = confint(best_model, level=0.99)
a2.CI.b1 = a2.CI[2,]
a2.CI.b1
confint(best_model, level = 0.99/g) #This uses the Bonferroni
a2.CI.sim = confint(best_model, level=0.99)
a2.CI.b1 = a2.CI[2,]
a2.CI.b1
a2.CI.b6r = a2.CI[3,]
a2.CI.b6s = a2.CI[4,]
a2.CI.b6r
summary(best_model)
a2.sum = summary(best_model)
a2.HT = a2.sum$coefficients
a2.HT
a2.HT[1]
a2.HT[2]
a2.b6s = a2.HT[4]
a2.b6s = a2.HT[4]
a2.b6s
a2.b0.t = a2.HT[1, 3]/2
a2.b0.t
a2.b0.p = a2.HT[1, 4]/2
a2.b5.p = a2.HT[2, 4]/2
a2.b6r.p = a2.HT[3, 4]/2
a2.b6s.p = a2.HT[4, 4]/2
a2.b0.p
ei.s = best_model$residuals/sqrt(sum(best_model$residuals^2)/(nrow(a2) - length(best_model$coefficients)))
ri = rstandard(best_model)
alpha = 0.1 ; n = nrow(a2); p = length(best_model$coefficients)
cutoff = qt(1-alpha/(2*n), n -p )
cutoff
cutoff.deleted = qt(1-alpha/(2*n), n -p -1 )
outliers = which(abs(ei.s)> cutoff | abs(ri) > cutoff | abs(ti) > cutoff.deleted)
ti = rstudent(best.model)
ti = rstudent(best_model)
alpha = 0.1
n = nrow(a2)
p = length(best_model$coefficients)
cutoff = qt(1-alpha/(2*n), n -p )
cutoff.deleted = qt(1-alpha/(2*n), n -p -1 )
outliers = which(abs(ei.s)> cutoff | abs(ri) > cutoff | abs(ti) > cutoff.deleted)
outliers
a2[outliers,]
ri
all.values = influence.measures(best_model)$infmat
colnames(all.values)
colnames(all.values)
a3 = a2[-outliers,]
nrow(a3)
a3 = a2[-outliers,]
full.model = lm(Y~ X1 + X2 + X3 + X4 + X5 + X6, data = a3)
empty.model = lm(Y ~ 1,data = a3)
FB.model.BIC = stepAIC(empty.model, scope = list(lower=empty.model, upper= full.model), k=log(n), direction="both", trace=FALSE)
best_model = FB.model.BIC
betas_1 = FB.model.BIC$coefficients
betas_1
FB.model.AIC = stepAIC(empty.model, scope = list(lower=empty.model, upper= full.model), k=2, direction="both", trace=FALSE)
FB.model.AIC
a <- read.csv("/Users/dukeletran/Documents/Dropbox/Documents/108 - STA, linear regression/Projects/project2/athlete.csv")
a <- read.csv("/Volumes/WD Red HDD/Duke/Dropbox/Documents/108 - STA, linear regression/HomeC:/Users/dletran/Dropbox/Documents/108 - STA, linear regression/Projects/project2/athlete.csv")
a <- read.csv("C:/Users/dletran/Dropbox/Documents/108 - STA, linear regression/Projects/project2/athlete.csv")
a <- read.csv("C:/Users/dletran/Dropbox/Documents/108 - STA, linear regression/Homework/project2/athlete.csv")
install.packages("gclus", dependencies = TRUE)
library(gclus) #for colored scatterplots matrices
a <- read.csv("C:/Users/dletran/Dropbox/Documents/108 - STA, linear regression/Homework/project2/athlete.csv")
library(ggplot2) #plot
library(gridExtra) #for multigrid scatterplots
library(gclus) #for colored scatterplots matrices
library(leaps) #for regsubset
library(MASS) #stepwise regression
install.packages("gclus", dependencies = TRUE)
install.packages("gclus", dependencies = TRUE)
