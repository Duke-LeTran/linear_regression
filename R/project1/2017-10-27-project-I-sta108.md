Statistical Analysis of Housing Prices and Square Footage in King county, Washington
================
Duke LeTran
October 27th, 2017

I. Introduction
===============

II. Summary of Data
===================

### Scatterplot - King County, Washington

![](R/project1/2017-10-27-project-I-sta108_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-3-1.png)

### Boxplot and Histograms - King County, Washington

![](R/project1/2017-10-27-project-I-sta108_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-4-1.png)

    ##      price          sqft_living  
    ##  Min.   :  90000   Min.   : 390  
    ##  1st Qu.: 333722   1st Qu.:1460  
    ##  Median : 460000   Median :1940  
    ##  Mean   : 566594   Mean   :2115  
    ##  3rd Qu.: 646250   3rd Qu.:2562  
    ##  Max.   :5570000   Max.   :9200

#### House Prices (Y)

-   Sample Mean: $566,594.00
-   Sample Median: $460,000.00
-   Sample Standard Deviation: $434,558.60

#### Square Footage (X)

-   Sample Mean: 2,115
-   Sample Median: 1,940
-   Sample Standard Deviation: 976.97

We see very clearly that this dataset is right-skewed for both random variables X and Y (as defined in the introduction). This is demonstrated in the boxplots by the outliers concentrated on the right and in the histograms by a right tail. This is further exemplefied by comparing the mean and the median, of which the mean is greater than the median for both random variables.

IIIa. Diagnostics - Initial Model
=================================

Based on our raw data, this is our estimated regression line:

*Y* = −120, 325.50 + 324.78*X*

We are 99% confident that that when our square footage (X) changes by 1 unit, the estimated change of housing prices (Y) increases between 289.5603785 and 359.9913638, on average. Since zero is not included in the confidence interval of *b*<sub>1</sub> and is strictly positive, a statistically significant positive relationship is suggested between housing prices(Y) and square footage(X).

Since there is a statistically significant positive relationship suggested, let's continue to examine if our data violates any of the following assumptions:

-   Homoscedasticity (constant variance)

-   Normality

### ASSESSING HOMOSCEDASTICITY

#### I. Distribution of Errors

![](R/project1/2017-10-27-project-I-sta108_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-7-1.png)

#### II. Fligner Killeen (FK) test

*H*<sub>0</sub> : *σ*<sub>*l*</sub><sup>2</sup> = *σ*<sub>*u*</sub><sup>2</sup>

*H*<sub>0</sub> : *σ*<sub>*l*</sub><sup>2</sup> ≠ *σ*<sub>*u*</sub><sup>2</sup>

    ## 
    ##  Fligner-Killeen test of homogeneity of variances
    ## 
    ## data:  k$ei and k$Group
    ## Fligner-Killeen:med chi-squared = 21.663, df = 1, p-value =
    ## 3.25e-06

### ASSESSING NORMALITY

#### I. Histogram of *e*<sub>*i*</sub>

![](R/project1/2017-10-27-project-I-sta108_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-9-1.png)

#### II. QQ Plot

![](R/project1/2017-10-27-project-I-sta108_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-10-1.png)

#### III. Shapiro-Wilks Test

*H*<sub>0</sub>: The errors are normally distributed

*H*<sub>*A*</sub>: The errors are NOT normally distributed

    ## 
    ##  Shapiro-Wilk normality test
    ## 
    ## data:  k.ei
    ## W = 0.82829, p-value < 2.2e-16

### DISCUSSION - Diagnositics

*Assessing Homoscedasticity*

The scatterplot of errors versus fitted values clearly shows an ergregious violation of constant variance -- a distribution shape of a cone. Furthermore, our Fligner-Killeen test has rejected null hypothesis for all $= 0.10, 0.05, 0.1 $, which means we accept the alternative hypothesis that our variance of our lower half of the data does not equal the variance of our upper group of data.

-   Scatterplot of Errors vs. Fitted Values: **FAIL**

-   FK Test: **FAIL** (rejected *H*<sub>0</sub>)

Score: 0/2

*Assessing Normality*

Our histogram of *e*<sub>*i*</sub> confirms our initial scatterplot that our data is not normal but right-skewed. Our QQPlot has most of the points very close to the QQ line but deviates towards the higher square footage. Based on the QQPlot, there is at least one significant outlier. Though it would be nice to remove the higher X datapoints, they may provide additional information (so these will not be removed). Our Shapiro-Wilks Test has rejected the null hypothesis for all *α* = 0.10, 0.05, 0.1, which means that our data is non-normal -- though our sample number is relatively high (n = 500), in which case the test may be conservative. Let's proceed to remove the outlier to see if the fit of our data to the model improves.

-   Histogram of *e*<sub>*i*</sub>: **FAIL**

-   QQPlot: **SEMI-PASS**

-   SW Test: **FAIL** (rejected *H*<sub>0</sub>)

Score: 0.5/3

IIIb. Diagnostics - data with outliers removed
==============================================

#### REMOVING OUTLIERS

Since we know that We are defining outliers to be datapoint with an *e*<sub>*i*</sub> above 2 × 10<sup>6</sup>.

    ##               Estimate Std. Error   t value     Pr(>|t|)
    ## (Intercept) 71582.7915 24040.1555  2.977634 3.048395e-03
    ## sqft_living   221.5991    10.6787 20.751511 3.826672e-69

Removing the outlier, our new estimated regression line:

*Y* = 71, 582.79 + 221.6*X*

t

Note that our slope (*b*<sub>1</sub>) has decreased now that the outlier has been removed.

Since there is still a statistically significant positive relationship suggested, let's continue to re-examine our data to see if it violates any of the following assumptions:

-   Homoscedasticity (constant variance)

-   Normality

### ASSESSING HOMOSCEDASTICITY

#### I. Distribution of Errors

![](R/project1/2017-10-27-project-I-sta108_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-14-1.png)

#### II. Fligner Killeen (FK) test

*H*<sub>0</sub> : *σ*<sub>*l*</sub><sup>2</sup> = *σ*<sub>*u*</sub><sup>2</sup>

*H*<sub>0</sub> : *σ*<sub>*l*</sub><sup>2</sup> ≠ *σ*<sub>*u*</sub><sup>2</sup>

    ## 
    ##  Fligner-Killeen test of homogeneity of variances
    ## 
    ## data:  k2$ei and k2$Group
    ## Fligner-Killeen:med chi-squared = 23.866, df = 1, p-value =
    ## 1.033e-06

### ASSESSING NORMALITY

#### I. Histogram of *e*<sub>*i*</sub>

![](R/project1/2017-10-27-project-I-sta108_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-16-1.png)

#### II. QQ Plot

![](R/project1/2017-10-27-project-I-sta108_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-17-1.png)

#### III. Shapiro-Wilks Test

*H*<sub>0</sub>: The errors are normally distributed

*H*<sub>*A*</sub>: The errors are NOT normally distributed

    ## 
    ##  Shapiro-Wilk normality test
    ## 
    ## data:  k2.ei
    ## W = 0.93867, p-value = 2.23e-13

### DISCUSSION - Diagnostics (OUTLIER REMOVED)

*Assessing Homoscedasticity*

With our outlier removed, the scatterplot of errors versus fitted values has improved, though there is still a distinct sergregious violation of constant variance (cone shaped). Our Fligner-Killeen test still rejects null hypothesis for all $= 0.10, 0.05, 0.1 $.

-   Errors vs. Fitted Values: **FAIL**

-   FK Test: **FAIL** (rejected *H*<sub>0</sub>)

Score: 0/2

*Assessing Normality*

Our histogram of *e*<sub>*i*</sub> improved but still shows evidence of right-skewness. Our QQPlot has most of the points very close to the QQ line with no more outliers, so we will subjectively give this a pass (with much reservation). Our Shapiro-Wilks Test has rejected the null hypothesis again for all *α* = 0.10, 0.05, 0.1.

-   histogram of *e*<sub>*i*</sub>: **FAIL**

-   QQPlot: **PASS**

-   SW: **FAIL** (rejected *H*<sub>0</sub>)

Score: 1/3

IV. Analysis
============

#### Overview

-   Model Fit

-   Significant Linear Relationship

-   Diagnostics

#### I. Model Fit

    ## Analysis of Variance Table
    ## 
    ## Response: price
    ##              Df     Sum Sq    Mean Sq F value    Pr(>F)    
    ## sqft_living   1 1.8819e+13 1.8819e+13  430.63 < 2.2e-16 ***
    ## Residuals   491 2.1457e+13 4.3701e+10                      
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Our cooefficient of determination *R*<sup>2</sup> is 46.72%.

Thus, 46.72% of the variance in housing prices (Y) is explained by the linear relationship with square footage (X).

#### II. Significant linear Relationship

**Estimated Regression Line**

Our estimated regression line is:

*Y* = 71, 582.79 + 221.6*X*

**Hypothesis Testing of *b*<sub>1</sub>**

Our null hypothesis states (*H*<sub>0</sub>) that there is no negative linear relationship between housing prices (Y) and square footage(X), which is equivalent to *H*<sub>0</sub> ≤ 0.

Our alternative hypothesis states (*H*<sub>*A*</sub>) that there is a significant positive relationship between housing prices (Y) and square footage (X), which is equivalent to *H*<sub>*A*</sub> &gt; 0.

The t-statistics of b1 is 10.38, which can be interpreted as our sample slope (*b*<sub>1</sub> = 221.6) is 10.38 estimated standard errors away from the hypothesized slope of zero. Our p-value is 3.8266724 × 10<sup>−69</sup> which is less than all *α* = 0.10, 0.05, 0.01. Thus, we reject the null hypothesis.

Our conclusion, therefore, is that if there was no relationship or negative linear relationship between housing prices (Y) and square footage (Y), we find that our test-statistic (10.38) or more extreme with the probability of of 3.8266724 × 10<sup>−69</sup>.

Thus, we reject the null hypothesis and accept the alternative hypothesis that there is a significant positive linear relationship.

**Confidence interval of *b*<sub>1</sub>**

Our confidence interval for *b*<sub>1</sub>:

    ##    0.5 %   99.5 % 
    ## 193.9853 249.2130

We are 99% confident that when square footage(X) increases by 1 unit, housing prices (Y) increases between 193.9853 and 249.2130, on average. Since our confidence interval does not contain zero and is strictly positive, it suggests a statistically significant positive linear relationship, on average.

#### III. Diagnostics

For detailed analysis and interpretation, please see the Diagnostics section above. That section discusses each test and the ultimate decision to remove an outlier to form our new estimated regression line.

A summary is provided below:

*Assessing Homoscedasticity*

-   Scatterplot of Errors vs. Fitted Values: **FAIL**

-   FK Test: **FAIL** (rejected *H*<sub>0</sub>)

Score: 0/2

*Assessing Normality*

-   histogram of *e*<sub>*i*</sub>: **FAIL**

-   QQPlot: **PASS**

-   SW: **FAIL** (rejected *H*<sub>0</sub>)

Score: 1/3

V. Interpretation
=================

Our sample data (n = 500) of the houses in King County, Washington suggests that there is a statistically significant positive linear relationship between housing prices(Y) and square footage. Furthermore, we are 99% confident that when square footage(X) increases by 1 unit, housing prices (Y) increases between 193.9853 and 249.2130, on average.

However, based on the diagnostic tests assessing homoscedasticity and normality, our simple linear regression model has commited ergregious violations of our underlying assumptions.

The author of this paper highly recommends caution when using this model with the intent of accurately predicting housing prices based on square footage.

VI. Prediction Results
======================

As stated in the Interpretation section, the author of this paper highly recommends caution when using this model with the intent of accurately predicting housing prices based on square footage. However, we will proceed to make the following prediction anyways...

We will restate the estimated regression line here for reference:

*Y* = 71, 582.79 + 221.6*X*

#### Task 1 by client: Predict the average house price for houses with living square footage 2800.

Our predicted average house price for houses with living square footage 2800 is $692,060.40

We are 99% confident that, on average, houses with a living square footage of 2800 will sell in between the interval of $660,476.80 and $723,644.00

#### Task 2 by client: Predict the price of a particular house with living square footage 3200.

Our predicted average house price for a single house with living square footage 3200 is $780,700.10

We are 99% confident that, on average, a house with a living square footage of 3200 will sell in between the interval of $238,685.50 and $1,322,715.00

#### Task 3 by client: Predict the average house price for houses with living square footage 8000.

Our predicted average house price for houses with living square footage 8000 is $1,844,376.00

We are 99% confident that, on average, houses with a living square footage of 8000 will sell in between the interval of $1,678,864.00 and $2,009,888.00

VII. Conclusions
================

Based on our hypothesis testing and confidence interval, we see that there is a significant positive linear relationship between housing prices (Y) and square footage (X) of the homes in King County, Washington.

We note from a diagostics of our model that data fails mutiple assumption tests when assessing both homoscedasiticity and normality. Removal of the outlier significant improved the quality of our dataset but failed to rectify these ergregious violations.

From the original scatterplots, histograms, and boxplots, our inference that the data is right-skewed is confirmed by further assessing the QQplots, histogram of errors, and scatterplot of errors versus fitted values. This perhaps may be a suggestion that our model is more reliable under some unidentified value of square footage.

Please carefully consider these stated concerns when utilizing the predicted values of housing prices for the specified square footage.

### R Appendix Of Code

``` r
# Initialize - Read, Library
#k <- read.csv("C:/Users/dletran/Dropbox/Documents/108 - STA, linear regression/Projects/project1/KingCounty.csv") 
k <- read.csv("/Users/dukeletran/Documents/Projects/linear-regression/R/project1/KingCounty.csv") 
library(ggplot2)
library(gridExtra)

###### I. Introduction
n = nrow(k)
k_col = names(k)

###### II. Summary of Data
# Scatterplots
ggplot(k, aes(x = sqft_living, y = price)) +
  geom_smooth(method='lm', se = FALSE, color = "purple", size = 0.4) +
  geom_point(size=1, shape=18) +
  ggtitle("Home Prices vs. Square Footage") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ylab("Price (US dollars)") +
  xlab("Square Footage")
# Boxplots
b_sqft <- ggplot(k,
       aes(y = sqft_living, x = factor(""))) +
  geom_boxplot(fill = "white", colour = "#3366FF", outlier.color = "red", outlier.shape = 1) +
  ylab("sqft_living") +
  xlab(" ") +
  coord_flip() + #flips it from vertical to sideways plots
  ggtitle("X: Square Footage") +
  theme(plot.title = element_text(hjust = 0.5)) +#centers the title
  stat_boxplot(geom ='errorbar')
b_price <- ggplot(k,
       aes(y = price, x = factor(""))) +
  geom_boxplot(fill = "white", colour = "#3366FF", outlier.color = "red", outlier.shape = 1) +
  ylab("price") +
  xlab(" ") +
  coord_flip() + #flips it from vertical to sideways plots
  ggtitle("Y: House Prices") +
  theme(plot.title = element_text(hjust = 0.5)) +#centers the title
  stat_boxplot(geom ='errorbar')
# Histograms
h_price <- ggplot(k,
       aes(x = price)) + 
  geom_histogram(binwidth = 80000, color = "black",fill = "white") + 
  xlab("price") + 
  ggtitle("Y: House Prices") +
  theme(plot.title = element_text(hjust = 0.5))
h_sqft <- ggplot(k,
       aes(x = sqft_living)) + 
  geom_histogram(binwidth = 150, color = "black",fill = "white") + 
  xlab("X: sqft_living") + 
  ggtitle("Square Footage") +
  theme(plot.title = element_text(hjust = 0.5))
# mutiplot
grid.arrange(b_price, h_price, b_sqft, h_sqft, ncol=2)
# Summary of Data
summary(k)
k_var_price = var(k$price)
k_var_sqft = var(k$sqft_living)
k_std_price = sd(k$price)
k_std_sqft = sd(k$sqft_living)

###### IIIa. Diagnostics - Initial Model
#simple linear model
k_model = lm(price ~ sqft_living, data=k)
#initialize for diagnostics
k.sum = summary(k_model)
k.HT = k.sum$coefficients
k.b1 = round(k.HT[2,1], 2)
k.b0 = round(k.HT[1,1], 2)
k.sb1 = round(k.HT[2,2], 2)
k$ei = k_model$residuals
k$yhat = k_model$fitted.values
#quick check to see if there a significant linear relationship for b1
####confidence intervals
k.CI = confint(k_model, level = 0.99)
k.CI.b1 = k.CI[2,]
##ASSESSING HOMOSCEDASITICITY
#i.Distribution of Errors
ggplot(k, 
       aes(x = yhat, y = ei)) +
  geom_smooth(method='lm', se = FALSE, color = "green", size = 0.4) +
  geom_point(size=1, shape=18) +
  ggtitle("Errors vs. Fitted Values") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ylab("Errors") +
  xlab("Fitted Values")
#ii.Fligner Killeen Test
Group = rep("Lower",nrow(k))
Group[k$price > median(k$price)] = "Upper"
Group = as.factor(Group)
k$Group = Group
k.FKtest = fligner.test(k$ei, k$Group)
k.FKtest
##ASSESSING NORMALITY
#i.histogram of ei
ggplot(k,
       aes(x = ei)) + 
  geom_histogram(binwidth = 100000, color = "black",fill = "white") + 
  xlab("ei") + 
  ggtitle("Residuals") +
  theme(plot.title = element_text(hjust = 0.5))
#ii. qqplot
qqnorm(k_model$residuals)
qqline(k_model$residuals)
#iii. shapiro-wilks test
k.ei = k_model$residuals
k.SWtest = shapiro.test(k.ei)
k.SWtest

###### IIIb.Diagnostics - data with outliers removed
#Removing Outliers
cutoff = 2.0 *10^6
outliers1 = which(k$price > cutoff | k$price < -cutoff)
k2 = k[-outliers1,]
#simple linear model - 2nd iteration (k2)
k_model = lm(price ~ sqft_living, data=k2)
#initialize for diagnostics
k2.sum = summary(k_model)
k2.HT = k2.sum$coefficients
k2.HT
k2.b1 = round(k2.HT[2,1], 2)
k2.b0 = round(k2.HT[1,1], 2)
k2.sb1 = round(k2.HT[2,2], 2)
k2.b1.t = round(k2.HT[2,3]/2, 2) #divide by 2 for one-tail test
k2.b1.p = k2.HT[2,4]
k2$ei = k_model$residuals
k2$yhat = k_model$fitted.values
#quick check to see if there a significant linear relationship for b1
#confidence intervals
k2.CI = confint(k_model, level = 0.99)
k2.CI.b1 = k2.CI[2,]
##ASSESSING HOMOSCEDASTICITY 
#i. distribution of errors
ggplot(k2, 
       aes(x = yhat, y = ei)) +
  geom_smooth(method='lm', se = FALSE, color = "green", size = 0.4) +
  geom_point(size=1, shape=18) +
  ggtitle("Errors vs. Fitted Values") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ylab("Errors") +
  xlab("Fitted Values")
#ii.fligner killeen test
Group = rep("Lower",nrow(k2))
Group[k2$price > median(k2$price)] = "Upper"
Group = as.factor(Group)
k2$Group = Group
k2.FKtest = fligner.test(k2$ei, k2$Group)
k2.FKtest
##ASSESSSING NORMALITY
#i.histogram of ei
ggplot(k2,
       aes(x = ei)) + 
  geom_histogram(binwidth = 50000, color = "black",fill = "white") + 
  xlab("ei") + 
  ggtitle("Residuals") +
  theme(plot.title = element_text(hjust = 0.5))
#ii. qqplot
qqnorm(k_model$residuals)
qqline(k_model$residuals)
#iii. shapiro-wilks test
k2.ei = k_model$residuals
k2.SWtest = shapiro.test(k2.ei)
k2.SWtest

##### IV. Analysis
#i.Model Fit
k_table = anova(k_model)
k_table
SSE = k_table[2,2]
SSR = k_table[1,2]
SSTO = SSE + SSR
R2 = round(SSR/SSTO * 100, 2)
#confidence interval for b1
k2.CI.b1

#V. Interpretation
#No code was used in interpretation

##### VI. Prediction Results - Initialize
xs.1 = data.frame(sqft_living = 2800)
xs.2 = data.frame(sqft_living = 3200)
xs.3 = data.frame(sqft_living = 8000)
#Task 1 by client
ys.1.CI = predict(k_model, xs.1, interval = "confidence", level = 0.99)
#Task 2 by client
ys.2.PI = predict(k_model, xs.2, interval = "prediction", level = 0.99)
#Task 3 by client
ys.3.CI = predict(k_model, xs.3, interval = "confidence", level = 0.99)

##### VII. Conclusions
#No code was used in the conclusions
```
